---
title: "Testing based off of synthetic data tests"
output: html_notebook
---

## Imports

```{r message=FALSE, warning=FALSE}
library(here)
library(tidyverse)
library(cetcolor)
library(sf)
library(terra)
library(INLA)
library(INLAutils)
library(spdep)
```

## Data loading and pre-processing

```{r data-load, message=FALSE}
data_long = read_csv(here('data/paipr-long.csv')) %>% select(-...1) %>% 
  mutate(Year = as.integer(Year))
gdf_traces = st_read(here('data/traces.geojson')) %>% as_tibble() %>% st_as_sf()

# Remove points in far northern extent
accum_bnds = st_coordinates(gdf_traces)
gdf_traces = gdf_traces %>% st_crop(xmin=-1.5e6, xmax=max(accum_bnds[,1]),
                                    ymin=min(accum_bnds[,2]), ymax=max(accum_bnds[,2]))


# # Small-scale testing bounds
# gdf_traces = gdf_traces %>% st_crop(xmin=-1.4e6, xmax=-1.25e6,
#                                     ymin=min(accum_bnds[,2]), ymax=-3e5)



# Remove unrealistically high elevations and overly large accum sites
trace_drop = gdf_traces %>% filter(elev > 3000 | accum > 1000)

# Add East/North coordinates and drop filtered sites
pts_tmp = st_coordinates(gdf_traces)
coord_df = tibble(trace_ID = gdf_traces$trace_ID, East = pts_tmp[,1], North = pts_tmp[,2])
data = data_long %>% left_join(coord_df) %>% filter(!trace_ID %in% trace_drop$trace_ID)
gdf_traces = gdf_traces %>% filter(!trace_ID %in% trace_drop$trace_ID)
```

We need to import the other covariate data for the region.
This consists of topographic features from REMA and climatic variables from RACMO.
```{r}
REMA.dir = file.path("/media/durbank/WARP/Research/Antarctica/Data/DEMs/REMA/REMA_200m")
dem = rast(file.path(REMA.dir, "REMA_200m_dem.tif"))
crs(dem) = st_crs(gdf_traces)$wkt

slp = rast(file.path(REMA.dir, "REMA_200m_slope.tif"))
crs(slp) = crs(dem)

aspct = rast(file.path(REMA.dir, "REMA_200m_aspect.tif"))
crs(aspct) = crs(dem)

topo.stk = c(dem, slp, aspct)

topo.pts = extract(topo.stk, vect(gdf_traces$geometry)) %>% as_tibble() %>% 
  rename(dem=REMA_200m_dem) %>% 
  mutate(trace.ID=gdf_traces$trace_ID, aspect=sin(pi/180*aspect))
topo.pts = topo.pts %>% select(-ID)



RACMO.dir = file.path("/media/durbank/WARP/Research/Antarctica/Data", 
                      "/RACMO/2.3p2_yearly_ANT27_1979_2016/interim")
files = list.files(path = RACMO.dir, full.names = TRUE, 
                   pattern = "\\.tif$")

r.smb = rast(files[1])
names(r.smb) = 1979:2016
smb.pts = extract(r.smb, vect(gdf_traces$geometry)) %>% 
  as_tibble() %>% mutate(trace.ID=gdf_traces$trace_ID) %>% 
  pivot_longer(cols = num_range(prefix='', range=1979:2016), 
               names_to = 'Year', values_to = 'SMB') %>% 
  mutate(Year = as.integer(Year))


r.u10m = rast(files[2])
names(r.u10m) = 1979:2016
u10m.pts = extract(r.u10m, vect(gdf_traces$geometry)) %>% 
  as_tibble() %>% 
  pivot_longer(cols = num_range(prefix='', range=1979:2016), 
               names_to = 'Year', values_to = 'u10m') %>% 
  mutate(Year = as.integer(Year))


r.v10m = rast(files[3])
names(r.v10m) = 1979:2016
v10m.pts = extract(r.v10m, vect(gdf_traces$geometry)) %>% 
  as_tibble() %>% pivot_longer(cols = num_range(prefix='', range=1979:2016), 
                               names_to = 'Year', values_to = 'v10m') %>% 
  mutate(Year = as.integer(Year))

racmo.pts = smb.pts %>% 
  mutate(u10m=u10m.pts$u10m, v10m=v10m.pts$v10m) %>% 
  select(-ID)

data = data %>% 
  left_join(racmo.pts, by = c("trace_ID" = "trace.ID", "Year")) %>% 
  left_join(topo.pts, by = c("trace_ID" = "trace.ID"))

# data = data %>% mutate(S_x = abs(slope)*cos(asin(aspect)), 
#                        S_y = abs(slope)*aspect) %>% 
#   mutate(MSWD = S_x*u10m + S_y*v10m)

# Add columns for mean u10m and v10m speeds
mu.wind = data %>% group_by(trace_ID) %>% 
  summarize(mu.u10 = mean(u10m), mu.v10 = mean(v10m))
data = data %>% left_join(mu.wind, by = "trace_ID")
```

While I am testing/developing things, I'm only using a small subset of the data (around 1/2 a percent).
This still gives a few thousand observations to work with though.
Also for initial testing of everything, I am only including a single covariate (elevation).
Once I have a fully fleshed-out workflow though, I intend to add a few more (slope, wind vectors, etc.).
I center this covariate about its mean and also normalize the discrete time dimension, setting the min year as Year 1.

```{r}
set.seed(777)
gdf.tmp = gdf_traces %>% sample_frac(0.01)
data.tmp = data %>% filter(trace_ID %in% gdf.tmp$trace_ID) %>% 
  filter(Year >= 1979) %>% filter(Year < 2014) %>% arrange(trace_ID, Year)

# Select variables of interest
dat = data.tmp %>% select(trace_ID, East, North, Year, accum, 
                      std, elev, dem, slope, aspect, u10m, v10m, 
                      mu.u10, mu.v10)
# dat = data %>% select(trace_ID, East, North, Year, accum, 
#                       std, elev, dem, slope, aspect, u10m, v10m)

# Center covariates
yr.min = min(dat$Year)-1
dat = dat %>% 
  mutate(Year = Year-yr.min, elev = elev-mean(elev, na.rm=TRUE), 
         dem=dem-mean(dem, na.rm=TRUE), slope=slope-mean(slope, na.rm=TRUE), 
         u10m=u10m-mean(u10m, na.rm=TRUE), v10m=v10m-mean(v10m, na.rm=TRUE), 
         mu.u10=mu.u10-mean(mu.u10, na.rm=TRUE), mu.v10=mu.v10-mean(mu.v10, na.rm=TRUE))
         # u10m=mean(u10m, na.rm=TRUE), v10m=mean(v10m, na.rm=TRUE))

# Scale covariates by sd
dat = dat %>% 
  mutate(Year = Year, elev = elev/sd(elev), dem=dem/sd(dem), 
         slope=slope/sd(slope), u10m=u10m/sd(u10m), v10m=v10m/sd(v10m), 
         mu.u10=sd(mu.u10), mu.v10=sd(mu.v10))

# Split into training and testing sets
dat = dat %>% mutate(row.ID = 1:nrow(dat)) %>% relocate(row.ID)
dat.train = dat %>% slice_sample(prop = 0.80) %>% arrange(row.ID)
dat.test = dat %>% filter(!row.ID %in% dat.train$row.ID)
```

## INLA  modeling

I create the mesh used for defining the neighborhoods (this is important for generating the sparse precision matrix $Q$, enabling the GMRF approximation).
```{r}
mesh = inla.mesh.2d(loc = dat.train %>% select(East, North), 
                    max.edge = c(25000, 75000), cutoff = 5000)
plot(mesh)
points(dat.train %>% select(East, North), col = "red")

spde = inla.spde2.pcmatern(mesh = mesh, 
  prior.range = c(10000, 0.05), # P(range < 10 km) = 0.05
  prior.sigma = c(400, 0.05)) # P(sigma > 400 mm w.e.) = 0.05
```

```{r}
sptime.idx <- inla.spde.make.index('sptime.idx', spde$n.spde, 
                                     n.group = max(dat.train$Year))
A.sptime <- inla.spde.make.A(mesh, cbind(dat.train$East, dat.train$North), 
                             group = dat.train$Year)#, weights = dat.train$Year)

# Make data stack
dat.stack <- inla.stack(
  data = list(y = dat.train$accum),
  A = list(1, 1, A.sptime),
  # effects = list(list(Intercept = 1),
  effects = list(list(Intercept = rep(1, nrow(dat.train))),
                 tibble(elev = dat.train$elev, dem=dat.train$dem, 
                        slope=dat.train$slope, aspect=dat.train$aspect, 
                        u10m=dat.train$u10m, v10m=dat.train$v10m, 
                        Year=dat.train$Year), 
                 sptime.idx),
  tag = 'dat')
```

```{r}
# Prior on autoregressive rho parameter
time.spec = list(rho = list(prior = 'pc.cor1', param = c(0, 0.9)))

# Prior on fixed effects intercept (not currently implemented)
prior.fixed = list()

# Prior on precision parameter for Gamma observations
prec.prior = list(prior = 'pc.prec', param = c(250, 0.1)) #P(sigma > 250) = 10%

formula = y ~ -1 + Intercept + Year + 
  f(sptime.idx, 
    Year, 
    # as.numeric(sptime.idx$sptime.idx.group), 
    model = spde, group = sptime.idx.group, 
    control.group = list(model = 'ar1', hyper=time.spec))
```

## Fit model

```{r}
# mod = inla(formula,
#                     data = inla.stack.data(dat.stack),
#                     family = 'Gamma',
#                     quantiles = NULL,
#                     control.predictor = list(compute = TRUE, A = inla.stack.A(dat.stack), link = 1),
#                     # control.fixed = prior.fixed,
#                     control.family = list(hyper = list(prec = prec.prior)),
#                     control.compute = list(waic=TRUE, return.marginals.predictor=FALSE, config=TRUE))
```

### Alternative specification

This is the same model, but with the space and time random effects separated out to be wholly independent.
It still assumes that the temporal trends, however, vary spatially around a global fixed value.
```{r}
spde = inla.spde2.pcmatern(mesh = mesh, 
  prior.range = c(15000, 0.01), # P(range < 10 km) = 0.01
  prior.sigma = c(10, 0.05))

spde.yr = inla.spde2.pcmatern(mesh = mesh, 
  prior.range = c(5000, 0.01), # P(range < 10 km) = 0.01
  prior.sigma = c(1, 0.01), 
  constr = TRUE)

# Index for SPDE model and projector matrix
spat.idx = inla.spde.make.index(name = "spat.idx", n.spde = spde$n.spde)
A.spat = inla.spde.make.A(mesh = mesh, loc = cbind(dat.train$East, dat.train$North))

# Index for SPDE model and projector matrix
spYR.idx = inla.spde.make.index(name = "spYR.idx", n.spde = spde.yr$n.spde)
A.spYR = inla.spde.make.A(mesh = mesh, loc = cbind(dat.train$East, dat.train$North))

# Make data stack
dat.stack.iid <- inla.stack(
  data = list(y = dat.train$accum), 
  A = list(1, 1, 1, A.spat, A.spYR),
  effects = list(list(Intercept = rep(1, nrow(dat.train))), 
                 tibble(elev = dat.train$elev, dem=dat.train$dem, 
                        slope=dat.train$slope, aspect=dat.train$aspect, 
                        u10m=dat.train$u10m, v10m=dat.train$v10m, 
                        mu.u10=dat.train$mu.u10, mu.v10=dat.train$mu.v10, 
                        Year=dat.train$Year), 
                 list(time = dat.train$Year), 
                 spat.idx, 
                 spYR.idx),
  tag = 'dat')


time.spec = list(rho = list(prior = 'pc.cor1', param = c(0.3, 0.95)))
prior.fixed = list()
prec.prior = list(prior = 'pc.prec', param = c(250, 0.1)) #P(sigma > 250) = 10%


# form.iid = y ~ -1 + Intercept + dem + slope + 
#   # f(spat.idx, model = spde) + 
#   Year + f(spat.idx, Year, model = spde.yr) +
#   f(time, model = 'ar1', hyper = time.spec)

form.iid = y ~ -1 + Intercept + dem + 
  # slope +
  aspect + 
  # mu.u10 + mu.v10 + 
  # u10m + v10m + 
  f(spat.idx, model = spde) +
  Year + f(spYR.idx, Year, model = spde.yr) +
  # f(spat.idx, Year, model = spde.yr) +
  f(time, model = 'ar1', hyper = time.spec)
```

```{r}
mod.iid = inla(form.iid, 
               data = inla.stack.data(dat.stack.iid), 
               family = 'Gamma',
               quantiles = NULL, 
               control.predictor = list(compute = TRUE, A = inla.stack.A(dat.stack.iid), link = 1), 
               # control.fixed = prior.fixed, 
               control.family = list(hyper = list(prec = prec.prior)), 
               control.compute = list(waic=TRUE, return.marginals.predictor=TRUE, config=TRUE))

```


## Evalulate model performance

```{r}
summary(mod.iid)
```


```{r}

t.marg = function(mod.marg, t.func, param.names=NULL, n=100) {
  
  if (any(class(mod.marg) == "matrix")) {
    mod.marg = list(mod.marg)
    if (!is.null(param.names)) {
      names(mod.marg = param.names)
    } else {
      names(mod.marg) = "UNNAMED"
    }
  }
  
  if (is.null(param.names)) {
    param.names = names(mod.marg)
  }
  
    if (is.list(t.func) != TRUE) {
    t.func = list(t.func)
  }
  if (length(t.func) == 1) {
    t.func = rep(t.func, length(param.names))
  }
  
  # Preallocate output tbl
  out = tibble(x=numeric(), y=numeric(), Param=vector(mode="character"))
  
  marg.names = names(mod.marg)
  
  for (i in 1:length(marg.names)) {
    marg.i = inla.tmarginal(t.func[[i]], mod.marg[[param.names[i]]], n=n)
    out = out %>% bind_rows(tibble(x=marg.i[,1], y=marg.i[,2], Param=param.names[i]))
  }
  return(out)
}
```

```{r}
marg.fixed = t.marg(mod.iid$marginals.fixed, function(x) exp(x))
ggplot(marg.fixed, aes(x=x,y=y)) + geom_line() + facet_wrap(vars(Param), scales = "free")

marg.hyper = t.marg(mod.iid$marginals.hyperpar, function(x) (x))
ggplot(marg.hyper, aes(x=x,y=y)) + geom_line() + facet_wrap(vars(Param), scales = "free")

```



```{r}
Bi.sp = tibble(East = mesh$loc[,1], North = mesh$loc[,2], 
                 B.i = mod.iid$summary.random$spYR.idx$mean) %>% 
  mutate(B.tot = B.i+mod.iid$summary.fixed["Year",]$mean)
ggplot(Bi.sp) + geom_density(aes(x=B.tot))
# ggplot(Bi.sp) + geom_density(aes(x=B.i))

```

Compare results to a normal GLM to ensure correct interpretation
```{r}
# Formula without random variables
f.base = y ~ -1 + Intercept + Year + dem + aspect

# Fitting a frequentist GLM to data
mod.glm = glm(f.base, data = dat.train %>% rename(y=accum) %>% mutate(Intercept=1), 
               family = Gamma(link = "log"))

summary(mod.glm)
```

All of this looks good except for when looking at the individual summaries spatial random effects on the temporal trend.
In this case, the sd for individual estimates is some 4-5 orders of magnitude larger than the mean, making them virtually worthless.
This is visually shown in the below plot (and recall that this is the untransformed values, so after exponentiation this just becomes ridiculous).
```{r}
plot(mod.iid$marginals.random$spYR.idx$index.7, type='l')
```

